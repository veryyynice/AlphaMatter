{
  "cells": [
    {
      "cell_type": "raw",
      "id": "023635f2-71cf-43f2-a2e2-a7b4ced30a74",
      "metadata": {
        "id": "023635f2-71cf-43f2-a2e2-a7b4ced30a74"
      },
      "source": [
        "---\n",
        "sidebar_position: 2\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86fc5bb2-017f-434e-8cd6-53ab214a5604",
      "metadata": {
        "id": "86fc5bb2-017f-434e-8cd6-53ab214a5604"
      },
      "source": [
        "#  Retrieval Augmented Generation (RAG) App\n",
        "\n",
        "\n",
        "\n",
        "focus on **adding logic for incorporating historical messages.** This involves the management of a\n",
        "\n",
        "two approaches:\n",
        "\n",
        "1. [Chains](/docs/tutorials/qa_chat_history/#chains), in which we execute at most one retrieval step;\n",
        "2. [Agents](/docs/tutorials/qa_chat_history/#agents), in which we give an LLM discretion to execute multiple retrieval steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "487d8d79-5ee9-4aa4-9fdf-cd5f4303e099",
      "metadata": {
        "id": "487d8d79-5ee9-4aa4-9fdf-cd5f4303e099"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Components\n",
        "\n",
        "We will need to select three components from LangChain's suite of integrations.\n",
        "\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs customVarName=\"llm\" />"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UHvobCePAX6",
        "outputId": "81c61463-2bd8-4f34-dcb5-c7b6eac7c00f"
      },
      "id": "-UHvobCePAX6",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Try to get the API key from environment\n",
        "API_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "# os.environ[OPENAI_API_key] = \"my_value\"\n",
        "# If not found, prompt user securely\n",
        "if not API_key:\n",
        "    print(\"OpenAI API key not found in environment. Please enter it manually.\")\n",
        "    API_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = API_key\n",
        "\n",
        "# Final check: raise error if still not set\n",
        "if not API_key:\n",
        "    raise ValueError(\"OpenAI API key not provided. Set it in .env or enter it manually.\")\n"
      ],
      "metadata": {
        "id": "fmrzlev9v2Gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b44bfb-ed53-41ea-d3fb-2404265f1ad0"
      },
      "id": "fmrzlev9v2Gr",
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API key not found in environment. Please enter it manually.\n",
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fab0dd56-7437-4aeb-af20-7f420d47ca94",
      "metadata": {
        "id": "fab0dd56-7437-4aeb-af20-7f420d47ca94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e035ab-26b9-4f5d-a56f-86b50ed30242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.61 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.81.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.61->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.18-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.60\n",
            "    Uninstalling langchain-core-0.3.60:\n",
            "      Successfully uninstalled langchain-core-0.3.60\n",
            "Successfully installed langchain-core-0.3.63 langchain_openai-0.3.18\n"
          ]
        }
      ],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "!pip install langchain_openai\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
        "                 api_key = API_key\n",
        "\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da14773e-ac98-4a97-944b-4c6ec028d195",
      "metadata": {
        "id": "da14773e-ac98-4a97-944b-4c6ec028d195"
      },
      "source": [
        "import EmbeddingTabs from \"@theme/EmbeddingTabs\";\n",
        "\n",
        "<EmbeddingTabs/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4691bd31-d8f4-4ba1-aec5-44935400f33c",
      "metadata": {
        "id": "4691bd31-d8f4-4ba1-aec5-44935400f33c"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22fdc314-b91d-4820-b0a8-873b5b6e76f5",
      "metadata": {
        "id": "22fdc314-b91d-4820-b0a8-873b5b6e76f5"
      },
      "source": [
        "import VectorStoreTabs from \"@theme/VectorStoreTabs\";\n",
        "\n",
        "<VectorStoreTabs/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "137d3848-7265-4673-9779-4c5f604da469",
      "metadata": {
        "id": "137d3848-7265-4673-9779-4c5f604da469"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94bc335b-dc8a-4c40-aece-3aa9057cc6bd",
      "metadata": {
        "id": "94bc335b-dc8a-4c40-aece-3aa9057cc6bd"
      },
      "source": [
        "### Dependencies\n",
        "\n",
        "In addition, we'll use the following packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ede7fdc0-ef31-483d-bd67-32e4b5c5d527",
      "metadata": {
        "id": "ede7fdc0-ef31-483d-bd67-32e4b5c5d527"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --upgrade --quiet langgraph langchain-community beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e207ac1d-4a8e-4172-a9ee-3294519a9a40",
      "metadata": {
        "id": "e207ac1d-4a8e-4172-a9ee-3294519a9a40"
      },
      "source": [
        "### LangSmith (optional)\n",
        "\n",
        "LangChain will contain multiple steps with multiple invocations of LLM calls.  [LangSmith](https://smith.langchain.com) helps inspecting the llm and agent calls\n",
        "\n",
        "```python\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
        "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "rUY8nCrawU-O"
      },
      "id": "rUY8nCrawU-O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fa6ba684-26cf-4860-904e-a4d51380c134",
      "metadata": {
        "id": "fa6ba684-26cf-4860-904e-a4d51380c134"
      },
      "source": [
        "## Chains {#chains}\n",
        "\n",
        "Let's first revisit the vector store we built in [Part 1](/docs/tutorials/rag), which indexes an [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) blog post by Lilian Weng."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovWy7f9CSREJ",
        "outputId": "146abba2-dba4-4f13-b8b8-e16ecbf153c5"
      },
      "id": "ovWy7f9CSREJ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.63)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ffe06d69-33c9-4ca3-98fb-8c70cde9dba2",
      "metadata": {
        "id": "ffe06d69-33c9-4ca3-98fb-8c70cde9dba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5b546f-4c55-42c2-c488-43a9d37542ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "# Load and chunk contents of the blog\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDFS (optional)"
      ],
      "metadata": {
        "id": "U55J-e7G1M_o"
      },
      "id": "U55J-e7G1M_o"
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"test.pdf\" #set"
      ],
      "metadata": {
        "id": "zZve6z1pU86v"
      },
      "id": "zZve6z1pU86v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "#load into pages variable\n",
        "async def load_pdf(file_path):\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    pages = []\n",
        "    # for page in loader.load_and_split():\n",
        "    #     pages.append(page)\n",
        "    async for page in loader.alazy_load():\n",
        "          pages.append(page)\n",
        "    return pages\n",
        "#cite sources\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "pages = load_pdf(file_path)\n",
        "\n",
        "vector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\n",
        "docs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\n",
        "for doc in docs:\n",
        "    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')"
      ],
      "metadata": {
        "id": "Lsg5baVs08BS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "13e10e1d-b967-496b-cd4a-e997ab53d40d"
      },
      "id": "Lsg5baVs08BS",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'file_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-495f2f94a430>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#load into pages variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'file_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMAGES(optional)"
      ],
      "metadata": {
        "id": "48GcB8NW1XU4"
      },
      "id": "48GcB8NW1XU4"
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"test.pdf\" #set"
      ],
      "metadata": {
        "id": "3b3QdQ3CYc5i"
      },
      "id": "3b3QdQ3CYc5i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain_unstructured\n",
        "from langchain_unstructured import UnstructuredLoader\n",
        "\n",
        "loader = UnstructuredLoader(\n",
        "    file_path=file_path,\n",
        "    strategy=\"hi_res\",\n",
        "    partition_via_api=True,\n",
        "    coordinates=True,\n",
        ")\n",
        "docs = []\n",
        "for doc in loader.lazy_load():\n",
        "    docs.append(doc)"
      ],
      "metadata": {
        "id": "8d8lrdrc1WmX"
      },
      "id": "8d8lrdrc1WmX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vector Database**"
      ],
      "metadata": {
        "id": "zsKk7UydYJw0"
      },
      "id": "zsKk7UydYJw0"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b4369949-39f1-4cdc-b652-179e0b891b51",
      "metadata": {
        "id": "b4369949-39f1-4cdc-b652-179e0b891b51"
      },
      "outputs": [],
      "source": [
        "# Index chunks\n",
        "_ = vector_store.add_documents(documents=all_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c26d5f-1493-4ad6-9210-ea2723695149",
      "metadata": {
        "id": "42c26d5f-1493-4ad6-9210-ea2723695149"
      },
      "source": [
        "\n",
        "1. User input as a `HumanMessage`;\n",
        "2. Vector store query as an `AIMessage` with tool calls;\n",
        "3. Retrieved documents as a `ToolMessage`;\n",
        "4. Final response as a `AIMessage`.\n",
        "\n",
        "This model for state is so versatile that LangGraph offers a built-in version for convenience:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e27d97f0-27dc-438b-bf61-a403ca284522",
      "metadata": {
        "id": "e27d97f0-27dc-438b-bf61-a403ca284522"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35eeb6a1-29f2-4086-8b6f-8761cf24ce59",
      "metadata": {
        "id": "35eeb6a1-29f2-4086-8b6f-8761cf24ce59"
      },
      "source": [
        "\n",
        "\n",
        "> Human: \"What is Task Decomposition?\"\n",
        ">\n",
        "> AI: \"Task decomposition involves breaking down complex tasks into smaller and simpler steps to make them more manageable for an agent or model.\"\n",
        ">\n",
        "> Human: \"What are common ways of doing it?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8201a6ef-942f-4571-b3b9-55a430590266",
      "metadata": {
        "id": "8201a6ef-942f-4571-b3b9-55a430590266"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b03f752-d46d-4070-b790-197b742c4dc2",
      "metadata": {
        "id": "9b03f752-d46d-4070-b790-197b742c4dc2"
      },
      "source": [
        "\n",
        "Our graph will consist of three nodes:\n",
        "\n",
        "1. A node that fields the user input, either generating a query for the retriever or responding directly;\n",
        "2. A node for the retriever tool that executes the retrieval step;\n",
        "3. A node that generates the final response using the retrieved context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4d0ce8c9-b404-424b-886e-c1386368ec24",
      "metadata": {
        "id": "4d0ce8c9-b404-424b-886e-c1386368ec24"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    llm_with_tools = llm.bind_tools([retrieve])\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    system_message_content = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, say that you \"\n",
        "        \"don't know. Use three sentences maximum and keep the \"\n",
        "        \"answer concise.\"\n",
        "        \"\\n\\n\"\n",
        "        f\"{docs_content}\"\n",
        "    )\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "    # Run\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ac33f19c-7959-4526-8f12-0de76ae10387",
      "metadata": {
        "id": "ac33f19c-7959-4526-8f12-0de76ae10387"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5c7e1717-d262-4947-a64d-6b116e53856a",
      "metadata": {
        "id": "5c7e1717-d262-4947-a64d-6b116e53856a",
        "outputId": "956a88c6-ab8b-49fa-ed9c-7393049e3b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "236b6209-ee06-42ba-b266-d90d9cbf224b",
      "metadata": {
        "id": "236b6209-ee06-42ba-b266-d90d9cbf224b"
      },
      "source": [
        "\n",
        "# **Let's test our application.**\n",
        "Note that it responds appropriately to messages that do not require an additional retrieval step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4fbca953-970d-4271-be30-6c7799893dd1",
      "metadata": {
        "id": "4fbca953-970d-4271-be30-6c7799893dd1",
        "outputId": "bfb5ff08-1c9f-4468-8354-074cf217ef2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Hello\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df5046d-4610-4ffa-9f30-d04453da05a9",
      "metadata": {
        "id": "5df5046d-4610-4ffa-9f30-d04453da05a9"
      },
      "source": [
        "And when executing a search, we can stream the steps to observe the query generation, retrieval, and answer generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9ab78984-d7fa-40e1-a440-c041a6456c1f",
      "metadata": {
        "id": "9ab78984-d7fa-40e1-a440-c041a6456c1f",
        "outputId": "863771ac-f151-4736-9d00-4ce24fbf381b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_qzePJ3ObbYh8zU5iwGNargxJ)\n",
            " Call ID: call_qzePJ3ObbYh8zU5iwGNargxJ\n",
            "  Args:\n",
            "    query: Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subgoals. It can be achieved through techniques like chain of thought (CoT), which prompts models to think step by step, or through task-specific instructions. This helps in simplifying challenging tasks and provides insights into the reasoning process of the model.\n"
          ]
        }
      ],
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26a9c4d-0e5b-4db9-8b78-68624d829ac2",
      "metadata": {
        "id": "a26a9c4d-0e5b-4db9-8b78-68624d829ac2"
      },
      "source": [
        "Check out the LangSmith trace [here](https://smith.langchain.com/public/70110399-01d3-4b4b-9139-cbcd4edf9d6d/r)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2300c04-019c-4c65-a104-3dbf17c924b7",
      "metadata": {
        "id": "c2300c04-019c-4c65-a104-3dbf17c924b7"
      },
      "source": [
        "### Stateful management of chat history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e5cd784a-61b2-4f9c-ad92-3e555b33d0bf",
      "metadata": {
        "id": "e5cd784a-61b2-4f9c-ad92-3e555b33d0bf"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Specify an ID for the thread\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f557b169-b33c-42d0-b97e-1b948d0a2914",
      "metadata": {
        "id": "f557b169-b33c-42d0-b97e-1b948d0a2914"
      },
      "source": [
        "We can now invoke similar to before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c6d16477-52f5-4755-83d1-60eebddfaaa0",
      "metadata": {
        "id": "c6d16477-52f5-4755-83d1-60eebddfaaa0",
        "outputId": "fa9a2bfe-7d5b-49f2-967f-4f4e7582a13e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_AhebAsMnQ9SNYlwiq9CMiMLY)\n",
            " Call ID: call_AhebAsMnQ9SNYlwiq9CMiMLY\n",
            "  Args:\n",
            "    query: Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task decomposition involves breaking down a complicated task into smaller, manageable steps to facilitate planning and execution. Techniques like Chain of Thought (CoT) and Tree of Thoughts enhance this process by allowing models to think step by step or explore multiple reasoning possibilities simultaneously. This structured approach improves understanding and performance on complex tasks.\n"
          ]
        }
      ],
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config, # important for memory\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c9d6f0ee-b5a9-4141-9f6f-ad86a04e083f",
      "metadata": {
        "id": "c9d6f0ee-b5a9-4141-9f6f-ad86a04e083f",
        "outputId": "7efa5111-9270-408f-a615-e4c1aafba733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up some common ways of doing it?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_EzE3HmRpc7nKw8tWOMtKz51w)\n",
            " Call ID: call_EzE3HmRpc7nKw8tWOMtKz51w\n",
            "  Args:\n",
            "    query: common methods for task decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Common ways of performing task decomposition include: (1) using simple prompting techniques like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\", (2) task-specific instructions tailored to the activity at hand, such as \"Write a story outline\", and (3) incorporating human inputs for more context. Additionally, the LLM+P approach utilizes external classical planners and the Planning Domain Definition Language (PDDL) to generate structured plans for longer tasks.\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Can you look up some common ways of doing it?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbbeef2-d9a1-4857-874f-9f3b5cc4eca9",
      "metadata": {
        "id": "4bbbeef2-d9a1-4857-874f-9f3b5cc4eca9"
      },
      "source": [
        "Note that the query generated by the model in the second question incorporates the conversational context.\n",
        "\n",
        "The [LangSmith](https://smith.langchain.com/public/28e6179f-fc56-45e1-9028-447d76352c14/r) trace is particularly informative here, as we can see exactly what messages are visible to our chat model at each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0",
      "metadata": {
        "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0"
      },
      "source": [
        "## Agents {#agents}\n",
        "\n",
        "\n",
        "Below we assemble a minimal RAG agent. Using LangGraph's [pre-built ReAct agent constructor](https://langchain-ai.github.io/langgraph/how-tos/#langgraph.prebuilt.chat_agent_executor.create_react_agent), we can do this in one line.\n",
        "\n",
        "\n",
        " LangGraph's [Agentic RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/) tutorial for more advanced formulations.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "470d5996-527d-4ef1-9e31-2c259cc3c050",
      "metadata": {
        "id": "470d5996-527d-4ef1-9e31-2c259cc3c050"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d8f8734-5dcf-4058-a532-11c8a7d0efae",
      "metadata": {
        "id": "7d8f8734-5dcf-4058-a532-11c8a7d0efae"
      },
      "source": [
        "Let's inspect the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0907cef3-05cb-45c7-ab46-382c58c52eb1",
      "metadata": {
        "id": "0907cef3-05cb-45c7-ab46-382c58c52eb1",
        "outputId": "df946d26-5798-4156-d57e-7d90985d8a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98",
      "metadata": {
        "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98"
      },
      "source": [
        "The key difference from our earlier implementation is that instead of a final generation step that ends the run, here the tool invocation loops back to the original LLM call. The model can then either answer the question using the retrieved context, or generate another tool call to obtain more information.\n",
        "\n",
        "Let's test this out. We construct a question that would typically require an iterative sequence of retrieval steps to answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f48f92-bd91-4033-a01b-7bd0667e3d87",
      "metadata": {
        "id": "a2f48f92-bd91-4033-a01b-7bd0667e3d87",
        "outputId": "f746376b-df89-45ff-c2d0-057052ab3710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the standard method for Task Decomposition?\n",
            "\n",
            "Once you get the answer, look up common extensions of that method.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_75gTG6Ihu2LCiaeAvBmUc85b)\n",
            " Call ID: call_75gTG6Ihu2LCiaeAvBmUc85b\n",
            "  Args:\n",
            "    query: standard method for Task Decomposition\n",
            "  retrieve (call_otmT3iVYpmSTYF3sxKNFmX6H)\n",
            " Call ID: call_otmT3iVYpmSTYF3sxKNFmX6H\n",
            "  Args:\n",
            "    query: common extensions of Task Decomposition methods\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The standard method for task decomposition involves breaking down complex tasks into smaller, manageable steps. A commonly used approach in artificial intelligence is the **Chain of Thought (CoT)** technique, where the model is prompted to \"think step by step.\" This allows the model to decompose larger tasks into simpler sub-tasks, enhancing its performance and providing insight into its reasoning process.\n",
            "\n",
            "Some extensions of the task decomposition method include:\n",
            "\n",
            "1. **Tree of Thoughts**: This method builds on the Chain of Thought by exploring multiple reasoning possibilities at each stage. It generates a tree-like structure of thoughts by decomposing the problem into distinct thought steps and allowing for multiple thoughts per step.\n",
            "\n",
            "2. **LLM+P (Large Language Model with Planner)**: This approach incorporates external classical planners for long-horizon planning. It employs the Planning Domain Definition Language (PDDL) to translate the planning problem into this formal language, request a plan from an external planner, and then translate the plan back into natural language.\n",
            "\n",
            "3. **Direct Human Inputs**: Apart from automated methods, human intervention can also be utilized for task decomposition by providing specific instructions or guidance based on expertise.\n",
            "\n",
            "4. **Task-specific Instructions**: For certain tasks, unique prompts can be used to guide the decomposition, such as asking for a story outline when writing a novel.\n",
            "\n",
            "In summary, the standard task decomposition method is about transforming large tasks into smaller parts using well-defined structures and enhancements, making it more manageable and interpretable.\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
        "\n",
        "input_message = (\n",
        "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
        "    \"Once you get the answer, look up common extensions of that method.\"\n",
        ")\n",
        "\n",
        "for event in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b7c675-4011-43d2-9a6a-ddcf75fec536",
      "metadata": {
        "id": "97b7c675-4011-43d2-9a6a-ddcf75fec536"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}